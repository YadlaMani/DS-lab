{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "#Handling missing data\nimport pandas as pd\ndata={'Name':['Alice','Bob','Charile'],'Age':[25,None,35],'City':['New York','Los Angoles',None]}\ndf=pd.DataFrame(data)\nprint(df)\ndf_filled=df.fillna({'Age':df['Age'].mean(),'City':'Unknown'})\ndf_dropped=df.dropna()\nprint(df_filled)\nprint(df_dropped)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "<ipython-input-1-5396068419db>:2: DeprecationWarning: \nPyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\nbut was not found to be installed on your system.\nIf this would cause problems for you,\nplease provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n        \n  import pandas as pd\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "      Name   Age         City\n0    Alice  25.0     New York\n1      Bob   NaN  Los Angoles\n2  Charile  35.0         None\n      Name   Age         City\n0    Alice  25.0     New York\n1      Bob  30.0  Los Angoles\n2  Charile  35.0      Unknown\n    Name   Age      City\n0  Alice  25.0  New York\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": "#loading data\nimport pandas as pd\ndf=pd.read_csv('iris.csv')\nprint(\"Dataframe head:\\n\",df.head())\nprint(\"Dataframe info:\\n\",df.info())",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Dataframe head:\n    Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n0   1            5.1           3.5            1.4           0.2  Iris-setosa\n1   2            4.9           3.0            1.4           0.2  Iris-setosa\n2   3            4.7           3.2            1.3           0.2  Iris-setosa\n3   4            4.6           3.1            1.5           0.2  Iris-setosa\n4   5            5.0           3.6            1.4           0.2  Iris-setosa\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 150 entries, 0 to 149\nData columns (total 6 columns):\n #   Column         Non-Null Count  Dtype  \n---  ------         --------------  -----  \n 0   Id             150 non-null    int64  \n 1   SepalLengthCm  150 non-null    float64\n 2   SepalWidthCm   150 non-null    float64\n 3   PetalLengthCm  150 non-null    float64\n 4   PetalWidthCm   150 non-null    float64\n 5   Species        150 non-null    object \ndtypes: float64(4), int64(1), object(1)\nmemory usage: 6.5+ KB\nDataframe info:\n None\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": "#checking for missing values\nprint(\"Missing values:\\n\",df.isnull().sum())\ndf.fillna(df.select_dtypes(include=['number']).mean(),inplace=True)\ndf.dropna(inplace=True)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Missing values:\n Id               0\nSepalLengthCm    0\nSepalWidthCm     0\nPetalLengthCm    0\nPetalWidthCm     0\nSpecies          0\ndtype: int64\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 6
    },
    {
      "cell_type": "code",
      "source": "from sklearn.preprocessing import OneHotEncoder\nimport pandas as pd\n\n# Creating a sample DataFrame\ndata = pd.DataFrame({'color': ['Red', 'Green', 'Blue', 'Green']})\n\n# Defining the categories for OneHotEncoding\ncategories = [['Red', 'Green', 'Blue']]\n\n# Initializing OneHotEncoder with the predefined categories\nencoder = OneHotEncoder(categories=categories)\n\n# Fitting and transforming the data, and converting it to an array\nencoded_data = encoder.fit_transform(data[['color']]).toarray()\n\n# Creating a DataFrame from the encoded data with column names\nencoded_df = pd.DataFrame(encoded_data, columns=encoder.categories_[0])\n\n# Display the result\nprint(encoded_df)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "<ipython-input-2-c1f684a87df1>:2: DeprecationWarning: \nPyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\nbut was not found to be installed on your system.\nIf this would cause problems for you,\nplease provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n        \n  import pandas as pd\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "   Red  Green  Blue\n0  1.0    0.0   0.0\n1  0.0    1.0   0.0\n2  0.0    0.0   1.0\n3  0.0    1.0   0.0\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": "from sklearn.preprocessing import LabelEncoder\ndata=['Red','Green','Blue','Green']\nencoder=LabelEncoder()\nencoded_data=encoder.fit_transform(data)\nprint(encoded_data)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "[2 1 0 1]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "source": "from sklearn.preprocessing import OrdinalEncoder\nimport pandas as pd\n\n# Creating a sample DataFrame\ndata = pd.DataFrame({'size': ['small', 'medium', 'large', 'medium']})\n\n# Initializing OrdinalEncoder with predefined categories\nencoder = OrdinalEncoder(categories=[['small', 'medium', 'large']])\n\n# Fitting and transforming the data to get encoded values\nencoded_data = encoder.fit_transform(data[['size']])\n\n# Printing the encoded data as a NumPy array\nprint(encoded_data)\n\n# Optional: Convert encoded data to DataFrame with original column name\nencoded_df = pd.DataFrame(encoded_data, columns=['size_encoded'])\nprint(encoded_df)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "[[0.]\n [1.]\n [2.]\n [1.]]\n   size_encoded\n0           0.0\n1           1.0\n2           2.0\n3           1.0\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 6
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}